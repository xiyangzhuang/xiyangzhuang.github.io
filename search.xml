<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>行人重识别文献研究</title>
    <url>/2023/04/07/person-reidentification/</url>
    <content><![CDATA[<p>计算机视觉研究中，利用行人重识别技术可以判断同一个人是否在另一个地方被另一个传感器捕捉到。计算机视觉领域的学者们形象地将针对特定行人的监控视频检索问题称为行人重识别。随着公共安全的要求和摄像头等传感器设备被大规模被应用到主题公园，学校，街道，超市等场景中，传统的依靠人工的方式进行行人识别跟踪，需要大量的人力资本投入。同时，考虑到门店的建设成本，针对门店场景的行人重识别方法应考虑到算法的实施成本，这些都对行人的识别与跟踪，特别是在行人信息的高效检索等领域提出了新的挑战。</p>
<p>从技术上讲，实际视频监控系统的行人重识别系统可分为三个模块：行人检测，行人跟踪和行人信息检索。前两个任务是独立的计算机视觉任务，所以大家主要的工作还是最后一个模块。在行人重识别的研究中前期主要是围绕特定应用，进行特征提取，然后针对小规模数据集展开应用研究。近年来，随着数据量的增长以及深度学习研究的进一步推进，深度学习在行人识别检索的应用中取得了一定的成果。在门店场景顾客检索去重的研究中，对行人重识别提出了更高的要求。本文主要对从方法上对行人重识别做出一个大致的整理。
<span id="more"></span></p>
<h1 id="行人重识别基本原理">行人重识别基本原理</h1>
<p>行人重识别模型主通过使用单张图像作为输入与N张图像(g)进行匹配，这些图像的特征可描述为<span
class="math display">\[\left\{g_{i} \right\}_{i
=1}^{N}\]</span>，这N张图像属于N个不同的个体（ID）。给定一个个体q，其ID号<span
class="math display">\[i^{*}\]</span>可以通过以下公式获得：</p>
<p><span class="math display">\[
i^{*} = \text{argmax}_{i \in 1,2,\ldots,N}\text{sim}\left( q,\ g_{i}
\right)
\]</span></p>
<p>其中<span class="math display">\[\text{sim}\left( q,\
g_{i}\right)\]</span>是行人相似度度量函数，相似度最大的那个个体特征对应的ID即为所求的<em>i</em></p>
<h1 id="行人重识别门店场景可行性分析">行人重识别门店场景可行性分析</h1>
<p>1、 基于人脸识别进行行人重识别在门店场景中的应用可行性分析</p>
<p>理论上可行，但是有两个原因导致人脸识别较难应用：首先，广泛存在后脑勺和侧脸的情况，做正脸的人脸识别难。其次，摄像头拍摄的像素可能不高，尤其是远景摄像头里面人脸截出来很可能都没有达到32x32的像素。所以人脸识别在实际线下门店场景中的应用受到限制。</p>
<p>2、 基于衣服颜色的行人重识别在门店场景中的应用可行性分析</p>
<p>在行人重识别的过程中，衣服颜色确实是行人重识别做出判断一个重要因素，但光靠颜色是不足的。首先，摄像头之间是有色差，并且会有光照的影响。其次，有撞衫（颜色相似）的情况发生，要找细节，但比如颜色直方图这种统计的特征就把细节给忽略了。在门店顾客行人的重识别研究中，光用颜色特征是难以达到50%的top1正确率。</p>
<p>3、 直接将图像检索指标套用在行人重识别研究中是否合适</p>
<p>在早期，行人重识别数据集是由两个摄像头采集的比如viper，每个query只有一个正确的retrieval目标。所以往往使用top1比较。但在近期，随着大数据集的提出，数据集中往往包含多个摄像头的多个正确目标。光使用top1的话，不能反应模型的真实能力。所以类似图像检索，重识别加入了mAP（mean
average
precision）作为衡量标准，将排名为1~到n的结果（top1~n）都考虑进去。</p>
<p>4、测试方法可行性分析</p>
<p>目前行人重识别主要有两种方法。第一种方法是通过输入一对行人，输出这对行人的相似度，然后再按照相似度进行排序。第二种方法是提取特征，再计算与其他人的欧式距离，然后再按距离排序。</p>
<p>第一种方法的优点是，判断两个人是不是一个人，简单的二分类（是／否）。但缺点是如果我们搜索库中有m张图片，那么与目标图片组成m对图片对。每一对都要进一次模型，估算相似度，这极大的增加了测试的时间。如果我们有n个query，那么我们要计算nm次相似度（而m往往很大）。第二种方法是，预先提取行人的特征，我们只要预先提好n+m次特征。之后只要比较就好了，比较特征可以简单的用矩阵乘法实现。</p>
<p>通过搜索目前的研究成果，两种方案都有在用，但在门店客流场景中平台计算能力有限，因此用特征来快速检索更接近实际中图像搜索的要求。</p>
<!-- more -->
<h1 id="国内外研究文献整理">国内外研究文献整理</h1>
<p>行人重识别问题中的图片来源于不同的摄像头，然而，由于不同摄像头所处的角度、光照等环境的影响，行人重识别问题具有以下几个特点：由于实际监控环境中，无法使用脸部的有效信息，所以，只能利用行人的外貌特征来进行识别；在不同摄像头中，由于尺度、光照和角度的变化，同一个行人的不同图片中，外貌特征会有一定程度的变化；由于行人姿势及摄像头角度的变化，在不同摄像头中，不同行人的外貌特征可能比同一个人的外貌特征更相似。</p>
<p>学者从数据源将行人重识别问题分为基于影像的行人重识别技术和基于视频的行人重识别两类方法。本文为了搜索适用于门店客流场景的行人识别检索方法，重点围绕了基于特征表示、基于距离度量，基于深度学习技术在行人重别中的应用研究分别展开了讨论。</p>
<h2 id="基于特征表示的方法">基于特征表示的方法</h2>
<p>在视频监控环境中，行人的外貌特征比较容易提取和表示。因此，同一行人的不同外貌特征具有一定的鲁棒性。</p>
<p>1）(Dong, Cristani et al.
2011)为了减少视角变化导致的外貌变化，Farenzena M,
etal提出通过基于人身体对称性的特征提取方法。首先通过一个预处理过程在人身体上划分头、躯干、腿部和左右对称中轴，然后提取除了头部以外的各区域的多种特征，包括累积颜色特征和纹理特征。并基于对称中轴对特征进行加权，越靠近中轴权值越高[1]。</p>
<ol start="2" type="1">
<li>(Farenzena, Bazzani et
al.2010)l提出类似的方法，将绘画结构应用于行人重识别。用一个自适应的身体外形结构来表示行人像，包括头、胸、大腿和小腿，然后提取每个部分的颜色特征进行精确匹配[2]。</li>
</ol>
<p>3）(Bazzani, Cristani et
al.2012)结合行人的全局和局部外貌特征进行重识别，首先根据行人在单摄像头下的连续运动提取多个关键帧图像，并用多帧图像的累积HSV颜色直方图表示全局特征；其次，在把人身体分割成上、下半身并去除头部区域后，提取各上、下半身多帧图像中频繁出现的块信息表示局部特征；最后加权融合全局和局部特征进行行人重识别[3]。</p>
<h2 id="基于距离度量学习的方法">基于距离度量学习的方法</h2>
<p>上述基于特征的方法都是使用标准距离（如曼哈顿距离、欧氏距离和巴氏距离等）进行相似性度量。然而同一身份行人在跨越多个无重叠区摄像头时，不同外貌特征受视角、光照等因素的影响不同。标准的距离度量方法平等的对待每一种特征，而不会摒弃那些独立使用时效果很差的特征。因此，研究者尝试通过距离学习的方法，获得一个新的距离度量空间，使得同一行人不同图像的距离小于不同人间的距离。距离学习方法一般在马氏（Mahalanobis）距离的基础上进行，通过学习一个投影矩阵，使得在投影空间中同类样本之间的距离较小，而不同类样本之间的距离较大。</p>
<p>1）(Xing, Ng et
al.2002)提出距离测度学习的问题，他在Mahalanobis距离的基础上，根据样本的类别，将具有相同类别标签的样本组成正样本对，不同类别标签的样本构成负样本对，然后利用这些样本对作为约束条件来训练得到一个Mahalanobis矩阵，从而使得最终的距离度量函数能够尽可能地满足所给定的约束条件。[4]</p>
<p>2）(Weinberger and Saul 2009)提出最大近邻分类间隔(large marginnearest
neighbor
classification,LMNN)的算法，其思想类似于支持向量机，即希望寻求一个分类超平面，使得该超平面与最靠近点的距离尽可能大。同样，LMNN希望通过投影后，数据的邻域内的同类点向内部紧缩，不同类点向外扩张，并且之间的间隔尽可能大。[5]</p>
<p>3）(Dikmen, Akbas et al. 2010)对
LMNN进行改进提出LMNN-R方法，其用所有样本点的平均近邻边界来代替
LMNN中不同样本点所采用的各自近邻边界，取得了比LMNN
方法更强的约束效果。[6]</p>
<p>4）(Zheng, Gong et
al.2011)提出概率相对距离比较的方法，在学习距离度量函数时考虑相对约束，与之前的同类距离尽可能小，不同类距离尽可能大的要求不同，其要求同类的距离小于不同类之间的距离。对每一个样本，选择一个同类样本和不同类样本形成3元组，在训练过程通过最小化不同类样本距离减去同类样本距离的和，得到满足约束的距离度量矩阵。[7]</p>
<h2 id="基于神经网络的方法">基于神经网络的方法</h2>
<p>下述的方法主要基于神经网络来实现的，在这里从学者们的研究角度将行人重识别的思路大致分为基于人体部分的特征匹配和特征表达的损失函数设计两个方面。</p>
<h3 id="基于人体部分的特征匹配">基于人体部分的特征匹配</h3>
<p>基于人体部分的特征匹配，顾名思义，就是将人体看做是几个部分的组合，然后一部分一部分来比较。常见方案是水平切条，就是将图像切为几个水平的条。由于人体身材往往差不多，所以可以用简单的水平条来做一一比较[8-11]。在领域中做匹配，采用的是一个正方形的领域[12]。另一个较新的方案是先在人体上检测部件（手，腿，躯干等等）再进行匹配，这样的话可以减少位置的误差，但可能引入检测部件的误差[11,
13]。</p>
<h3
id="基于学习特征表达的损失函数设计">基于学习特征表达的损失函数设计</h3>
<p>为了便于说明我们这里首先介绍一下常用的损失函数。其实行人重识别训练大体上就是基于四种损失函数（loss），距离损失函数（distance
loss），分类损失函数（identification loss），验证损失函数（verification
loss），基于属性分类的损失函数（attributes loss）。distance
loss是最常用的loss，就是用feature之间的距离来计算loss，同一个人的feature应该更近，不同人的feature要更远，那么用同一个人的距离减掉不同人的距离加上一个正常数和0取max实现，代表的有triplet
loss，improved triplet loss，quadruplet loss等；identification
loss就是classification
loss，每一个人作为一个类别，来训练分类问题，把某个全连接层作为feature来做行人重识别，一般identification
loss能够很快收敛，但是面对百万级，千万级的数据稍显吃力；verification
loss就是两张图来做二分类，判断是否为同一个人，这个作为辅助训练还行，作为主训练的loss计算资源消耗巨大，其中constrastive
loss 就是其中的一种。在caffe的孪生神经网络（siamese
network）中，其采用的损失函数是contrastive loss；attributes
loss就是对于不同的属性做分类，比如上身颜色，是否戴帽子之类的，这个是有用的，但是标注数据太过奢侈。</p>
<p>对学者们近年来常用损失函数统计如下：(Zheng, Yang et al.
2016)采用identification
loss，直接通过拿身份Label来做多类分类来进行行人重识别[14]。(Li, Zhao et
al. 2014, Yi, Lei et al. 2014, Ahmed, Jones et al.
2015)采用的Verification loss来进行的行人重识别研究[8, 10, 12]。(Ding,
Lin et al. 2015, Hao, Feng et al.2017, Hermans, Beyer et al.
2017)采用的triplet loss来进行通过距离度量来进行行人重识别[15-17]。</p>
<h1 id="结论">结论</h1>
<p>在行人重识别的研究过程中，基于深度学习的方法成为当前的研究热点。上文就行人重识别采用的方法做了一个简要的总结。在进行人重识别之前要对行人进行检测，检测过程中涉及到检测算子的阈值问题，当阈值设得过为严格时，则检测会发生遗漏，减少参与匹配计算的影像数量，造成目标包含不全；当阈值设得过为宽松时，则可能会有更多的背景包含进去。这两种结果对行人重识别的结果都不好。另外一个方面就是如何在视频流中定位到个体出现的位置，这个任务要比行人检测、跟踪、重识别简单，不要求有那么高的检测精度，只要能定位就行。</p>
<p>另外在视频中进行行人跟踪相对简单，虽然不可避免的是会存在错误。但是，人脸识别、颜色、非背景信息都有利于提高行人跟踪的准确性。在追踪的过程中，行人会有比较大的变化。运用这些序列图来对行人重识别方法进行训练能大大减少监督学习对于标注数据的依赖。</p>
<p>近几年，主流方法是将检测算法得到的人视作由于多个部分组成的整体，利用深度学习预先对各个部分进行特征提取，然后通过相似性度量来判断行人是否出现过以前的某个位置。</p>
<h1 id="附录">附录</h1>
<p>这里主要列出行人去重数据集，其中，VIPeRk， Shinpuhkan，PRID，
i-LIDS，3DPeS，CUHK01~03这些的数据源有不同的场景，且只适用于单一场景，不能用于普适场景的表达。但这些数据集为门店去重数据集的构建提供一个参考依据，整理统计数据集如下表1所示。</p>
<blockquote>
<p>表1 行人去重数据集统计</p>
</blockquote>
<table>
<colgroup>
<col style="width: 24%" />
<col style="width: 9%" />
<col style="width: 13%" />
<col style="width: 9%" />
<col style="width: 23%" />
<col style="width: 10%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="header">
<th>数据集</th>
<th>个体数量</th>
<th>摄像头 数量</th>
<th>影像数量</th>
<th>标注方法</th>
<th>裁剪大小</th>
<th>多场景 捕捉</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VIPeR (2007)</td>
<td><strong>632</strong></td>
<td><strong>2</strong></td>
<td><strong>1264</strong></td>
<td><strong>Hand</strong></td>
<td><strong>128X48</strong></td>
<td></td>
</tr>
<tr class="even">
<td>ETH1,2,3 (2007)</td>
<td><strong>148</strong></td>
<td><strong>1</strong></td>
<td><strong>8580</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>QMUL iLIDS (2009)</td>
<td><strong>119</strong></td>
<td><strong>2</strong></td>
<td><strong>476</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>GRID (2009)</td>
<td><strong>1025</strong></td>
<td><strong>8</strong></td>
<td><strong>1275</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td></td>
</tr>
<tr class="odd">
<td>CAVIAR4ReID (2011)</td>
<td><strong>72</strong></td>
<td><strong>2</strong></td>
<td><strong>1220</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>3DPeS (2011)</td>
<td><strong>192</strong></td>
<td><strong>8</strong></td>
<td><strong>1011</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>PRID2011 (2011)</td>
<td><strong>934</strong></td>
<td><strong>2</strong></td>
<td><strong>24541</strong></td>
<td><strong>Hand</strong></td>
<td><strong>128X64</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>V47 (2011)</td>
<td><strong>47</strong></td>
<td><strong>2</strong></td>
<td><strong>752</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>WARD (2012)</td>
<td><strong>70</strong></td>
<td><strong>3</strong></td>
<td><strong>4786</strong></td>
<td><strong>Hand</strong></td>
<td><strong>128X48</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>SAIVT-Softbio (2012)</td>
<td><strong>152</strong></td>
<td><strong>8</strong></td>
<td><strong>64472</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>CUHK01 (2012)</td>
<td><strong>971</strong></td>
<td><strong>2</strong></td>
<td><strong>3884</strong></td>
<td><strong>Hand</strong></td>
<td><strong>160X60</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>CUHK02 (2013)</td>
<td><strong>1816</strong></td>
<td><strong>10(5-pairs)</strong></td>
<td><strong>7264</strong></td>
<td><strong>Hand</strong></td>
<td><strong>160X60</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>CUHK03 (2014)</td>
<td><strong>1467</strong></td>
<td><strong>10(5 pairs)</strong></td>
<td><strong>13164</strong></td>
<td><strong>Hand/DPM</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>RAiD (2014)</td>
<td><strong>43</strong></td>
<td><strong>4</strong></td>
<td><strong>6920</strong></td>
<td><strong>Hand</strong></td>
<td><strong>128X64</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>iLIDS-VID (2014)</td>
<td><strong>300</strong></td>
<td><strong>2</strong></td>
<td><strong>42495</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>MPR Drone (2014)</td>
<td><strong>84</strong></td>
<td><strong>1</strong></td>
<td></td>
<td><strong>Pyramid Features(ACF)</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>HDA Person Dataset (2014)</td>
<td><strong>53</strong></td>
<td><strong>13</strong></td>
<td><strong>2976</strong></td>
<td><strong>Hand/Pyramid Features(ACF)</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>Shinpuhkan Dataset (2014)</td>
<td><strong>24</strong></td>
<td><strong>16</strong></td>
<td></td>
<td><strong>Hand</strong></td>
<td><strong>128X48</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>CASIA Gait Database B (2015)</td>
<td><strong>124</strong></td>
<td><strong>11</strong></td>
<td></td>
<td><strong>Background subtraction</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>Market1501 (2015)</td>
<td><strong>1501</strong></td>
<td><strong>6</strong></td>
<td><strong>32217</strong></td>
<td><strong>Hand/DPM</strong></td>
<td><strong>128X64</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>PRW (2016)</td>
<td><strong>932</strong></td>
<td><strong>6</strong></td>
<td><strong>34304</strong></td>
<td><strong>Hand</strong></td>
<td><strong>vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>Large scale person search (2016)</td>
<td><strong>11934s</strong></td>
<td><strong>-</strong></td>
<td><strong>34574</strong></td>
<td><strong>Hand</strong></td>
<td><strong>vary</strong></td>
<td></td>
</tr>
<tr class="odd">
<td>MARS (2016)</td>
<td><strong>1261</strong></td>
<td><strong>6</strong></td>
<td><strong>1191003</strong></td>
<td><strong>DPM+GMMCP</strong></td>
<td><strong>256X128</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>DukeMTMC-reID (2017)</td>
<td><strong>1812</strong></td>
<td><strong>8</strong></td>
<td><strong>36441</strong></td>
<td><strong>Hand</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="odd">
<td>DukeMTMC4ReID (2017)</td>
<td><strong>1852</strong></td>
<td><strong>8</strong></td>
<td><strong>46261</strong></td>
<td><strong>Doppia</strong></td>
<td><strong>Vary</strong></td>
<td><strong>✔</strong></td>
</tr>
<tr class="even">
<td>Airport (2017)</td>
<td><strong>9651</strong></td>
<td><strong>6</strong></td>
<td><strong>39902</strong></td>
<td><strong>ACF</strong></td>
<td><strong>128X64</strong></td>
<td><strong>✔</strong></td>
</tr>
</tbody>
</table>
<p>参考文献</p>
<p>[1] DONG S C, CRISTANI M, STOPPA M, et al. Custom Pictorial
Structures for Re-identification; proceedings of the British Machine
Vision Conference, F, 2011 [C].</p>
<p>[2] FARENZENA M, BAZZANI L, PERINA A, et al. Person re-identification
by symmetry-driven accumulation of local features; proceedings of the
Computer Vision and Pattern Recognition, F, 2010 [C].</p>
<p>[3] BAZZANI L, CRISTANI M, PERINA A, et al. Multiple-shot person
re-identification by chromatic and epitomic analyses [J]. Pattern
Recognition Letters, 2012, 33(7): 898-903.</p>
<p>[4] XING E P, NG A Y, JORDAN M I, et al. Distance metric learning,
with application to clustering with side-information; proceedings of the
International Conference on Neural Information Processing Systems, F,
2002 [C].</p>
<p>[5] WEINBERGER K Q, SAUL L K. Distance Metric Learning for Large
Margin Nearest Neighbor Classification [M]. JMLR.org, 2009.</p>
<p>[6] DIKMEN M, AKBAS E, HUANG T S, et al. Pedestrian Recognition with
a Learned Metric [J]. Lecture Notes in Computer Science, 2010,
6495(501-12.</p>
<p>[7] ZHENG W S, GONG S, XIANG T. Person re-identification by
probabilistic relative distance comparison; proceedings of the Computer
Vision and Pattern Recognition, F, 2011 [C].</p>
<p>[8] LI W, ZHAO R, XIAO T, et al. DeepReID: Deep Filter Pairing Neural
Network for Person Re-identification; proceedings of the Computer Vision
and Pattern Recognition, F, 2014 [C].</p>
<p>[9] LIAO S, HU Y, ZHU X, et al. Person re-identification by Local
Maximal Occurrence representation and metric learning; proceedings of
the Computer Vision and Pattern Recognition, F, 2015 [C].</p>
<p>[10] YI D, LEI Z, LIAO S, et al. Deep Metric Learning for Person
Re-identification; proceedings of the International Conference on
Pattern Recognition, F, 2014 [C].</p>
<p>[11] ZHAO R, OUYANG W, WANG X. Person Re-identification by Salience
Matching; proceedings of the IEEE International Conference on Computer
Vision, F, 2013[C].</p>
<p>[12] AHMED E, JONES M, MARKS T K. An improved deep learning
architecture for person re-identification; proceedings of the Computer
Vision and Pattern Recognition, F, 2015 [C].</p>
<p>[13] ZHENG L, HUANG Y, LU H, et al. Pose Invariant Embedding for Deep
Person Re-identification [J]. 2017.</p>
<p>[14] ZHENG L, YANG Y, HAUPTMANN A G. Person Re-dentification: Past,
Present and Future [J]. 2016,</p>
<p>[15] HAO L, FENG J, QI M, et al. End-to-End Comparative Attention
Networks for Person Re-Identification [J]. IEEE Transactions on Image
Processing A Publication of the IEEE Signal Processing Society, 2017,
26(7): 3492-506.</p>
<p>[16] HERMANS A, BEYER L, LEIBE B. In Defense of the Triplet Loss for
Person Re-Identification [J]. 2017,</p>
<p>[17] DING S, LIN L, WANG G, et al. Deep feature learning with
relative distance comparison for person re-identification [J]. Pattern
Recognition, 2015, 48(10):2993-3003.</p>
]]></content>
      <categories>
        <category>articles</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>How to build gui with python</title>
    <url>/2023/04/07/how-to-build-gui-with-python/</url>
    <content><![CDATA[<p>为了方便测试我们搭建的界面和构建一下小应用，该应用获取服务器字符串，端口号，文件名（路径），并将它保存在get_filepath_from_server.py,由于本应用仅供测试使用，其代码简单如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">helptxt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">get_filepath_from_server.py -file fffffff [-port number] [-server server|localhost]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">defaultServer = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">defaultPort = <span class="string">&#x27;80&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_command_line</span>():</span><br><span class="line">    <span class="built_in">dict</span> = &#123;&#125;                          <span class="comment">#put in dict for easy finding</span></span><br><span class="line">    args = sys.argv[<span class="number">1</span>:]                <span class="comment">#skip program name at front of the args</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(args) &gt;= <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">dict</span>[args[<span class="number">0</span>]] = args[<span class="number">1</span>]         <span class="comment">#examle dict[&#x27;-server&#x27;]=&#x27;localhost&#x27;</span></span><br><span class="line">        args = args[<span class="number">2</span>:]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dict</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_filepath_from_server</span>(<span class="params">server, port, file</span>):</span><br><span class="line">   <span class="keyword">return</span> server + <span class="string">&quot;:&quot;</span> + port + <span class="string">&quot;:&quot;</span> + file</span><br><span class="line">     </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">      </span><br><span class="line">    server = args.get(<span class="string">&#x27;-server&#x27;</span>, defaultServer)</span><br><span class="line">    port = args.get(<span class="string">&#x27;-port&#x27;</span>, defaultPort)</span><br><span class="line">    filepath = args.get(<span class="string">&#x27;-file&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> filepath == <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(helptext)</span><br><span class="line">      </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    args = parse_command_line()</span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>假设大家对Python3界面搭建有一个基本的了解，下面分别介绍使用行框架和命令行，网格，复用表单三种搭建界面的方法。对于追求代码通用性的应该果断舍弃前两种方案。</p>
<p>1）使用行框架和命令行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">helptxt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">get_filepath_from_server.py -file fffffff [-port number] [-server server|localhost]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tkinter.messagebox <span class="keyword">import</span> showinfo</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">onReturnKey</span>():</span><br><span class="line">    cmdline = (<span class="string">&#x27;python get_filepath_from_server.py -server %s -port -%s -host %s&#x27;</span>%</span><br><span class="line">                (content[<span class="string">&#x27;File&#x27;</span>].get(),</span><br><span class="line">                content[<span class="string">&#x27;Port&#x27;</span>].get(),</span><br><span class="line">                content[<span class="string">&#x27;Server&#x27;</span>].get()))</span><br><span class="line">    os.system(cmdline)</span><br><span class="line">    showinfo(<span class="string">&#x27;getfilegui-1&#x27;</span>, <span class="string">&#x27;Process complete&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">box = Tk()</span><br><span class="line">labels = [<span class="string">&#x27;Server&#x27;</span>, <span class="string">&#x27;Port&#x27;</span>, <span class="string">&#x27;File&#x27;</span>]</span><br><span class="line">content = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">    row = Frame(box)</span><br><span class="line">    row.pack(fill=X)</span><br><span class="line">    Label(row, text=label, width=<span class="number">6</span>).pack(side=LEFT)</span><br><span class="line">    entry = Entry(row)</span><br><span class="line">    entry.pack(side=RIGHT, expand=YES, fill=X)</span><br><span class="line">    content[label] = entry</span><br><span class="line"> </span><br><span class="line">box.title(<span class="string">&#x27;getfilegui-1&#x27;</span>)</span><br><span class="line">box.bind(<span class="string">&#x27;&lt;Return&gt;&#x27;</span>, (<span class="keyword">lambda</span> event: onReturnKey()))</span><br><span class="line">mainloop()</span><br></pre></td></tr></table></figure>
<p>2）使用网格和函数调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">helptxt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">get_filepath_from_server.py -file fffffff [-port number] [-server server|localhost]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> get_filepath_from_server</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tkinter.messagebox <span class="keyword">import</span> showinfo</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">onSubmit</span>():</span><br><span class="line">    get_filepath_from_server.get_filepath_from_server(content[<span class="string">&#x27;Server&#x27;</span>].get(),</span><br><span class="line">                                    content[<span class="string">&#x27;Port&#x27;</span>].get(),</span><br><span class="line">                                    content[<span class="string">&#x27;File&#x27;</span>].get())</span><br><span class="line">    showinfo(<span class="string">&#x27;getfilegui-2&#x27;</span>, <span class="string">&quot;process complete&quot;</span>)</span><br><span class="line"> </span><br><span class="line">     </span><br><span class="line">box= Tk()</span><br><span class="line">labels = [<span class="string">&#x27;Server&#x27;</span>, <span class="string">&#x27;Port&#x27;</span>, <span class="string">&#x27;File&#x27;</span>]</span><br><span class="line">rownum =<span class="number">0</span></span><br><span class="line">content = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">    Label(box, text=label).grid(column=<span class="number">0</span>, row=rownum)</span><br><span class="line">    entry = Entry(box)</span><br><span class="line">    entry.grid(column=<span class="number">1</span>, row=rownum, sticky=E+W)</span><br><span class="line">    content[label] = entry</span><br><span class="line">    rownum += <span class="number">1</span></span><br><span class="line">     </span><br><span class="line">box.columnconfigure(<span class="number">0</span>, weight=<span class="number">0</span>)</span><br><span class="line">box.columnconfigure(<span class="number">1</span>, weight=<span class="number">1</span>)</span><br><span class="line">Button(text=<span class="string">&#x27;Submit&#x27;</span>, command=onSubmit).grid(row=rownum, column=<span class="number">0</span>, columnspan=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">box.title(<span class="string">&#x27;getfilegui-2&#x27;</span>)</span><br><span class="line">box.bind(<span class="string">&#x27;&lt;Return&gt;&#x27;</span>, (<span class="keyword">lambda</span> event: onSubmit()))</span><br><span class="line">mainloop()</span><br></pre></td></tr></table></figure>
<p>3）使用可利用的表单布局类：</p>
<p>示例代码1：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line">entrysize = <span class="number">40</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Form</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, labels, parent=<span class="literal">None</span></span>):</span><br><span class="line">        labelsize = <span class="built_in">max</span>(<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> labels) + <span class="number">2</span></span><br><span class="line">        box = Frame(parent)</span><br><span class="line">        box.pack(expand=YES, fill=X)</span><br><span class="line">        rows = Frame(box, bd =<span class="number">2</span>, relief=GROOVE)</span><br><span class="line">        rows.pack(side=TOP, expand=YES, fill=X)</span><br><span class="line">        self.content = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">            row = Frame(rows)</span><br><span class="line">            row.pack(fill=X)</span><br><span class="line">            Label(row, text=label, width=labelsize).pack(side=LEFT)</span><br><span class="line">            entry = Entry(row, width=entrysize)</span><br><span class="line">            entry.pack(side=RIGHT, expand=YES, fill=X)</span><br><span class="line">            self.content[label] = entry</span><br><span class="line">        Button(box, text=<span class="string">&#x27;Cancel&#x27;</span>, command=self.onCancel).pack(side=RIGHT)</span><br><span class="line">        Button(box, text=<span class="string">&#x27;Submit&#x27;</span>, command=self.onSubmit).pack(side=RIGHT)</span><br><span class="line">        box.master.bind(<span class="string">&#x27;&lt;Return&gt;&#x27;</span>, (<span class="keyword">lambda</span> event: self. onSubmit()))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">onSubmit</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> self.content:</span><br><span class="line">            <span class="built_in">print</span>(key, <span class="string">&#x27;\t=&gt;\t&#x27;</span>, self.content[key].get())</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">onCancel</span>(<span class="params">self</span>):</span><br><span class="line">        Tk.quit()</span><br><span class="line"> </span><br><span class="line">         </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DynamicForm</span>(<span class="title class_ inherited__">Form</span>):    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, labels=<span class="literal">None</span></span>):</span><br><span class="line">        labels = <span class="built_in">input</span>(<span class="string">&#x27;Enter field names:&#x27;</span>).split()</span><br><span class="line">        Form.__init__(self, labels)</span><br><span class="line">         </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">onSubmit</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Field Values...&#x27;</span>)</span><br><span class="line">        Form.onSubmit(self)</span><br><span class="line">        self.onCancel()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> sys</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) == <span class="number">1</span>:</span><br><span class="line">        Form([<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Job&#x27;</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        DynamicForm()</span><br><span class="line">    mainloop()</span><br></pre></td></tr></table></figure>
<p>示例代码2：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">getfilegui.py</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> form <span class="keyword">import</span> Form</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> Tk, mainloop</span><br><span class="line"><span class="keyword">from</span> tkinter.messagebox <span class="keyword">import</span> showinfo</span><br><span class="line"><span class="keyword">import</span> get_filepath_from_server, os</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GetFilePathForm</span>(<span class="title class_ inherited__">Form</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, oneshot=<span class="literal">False</span></span>):</span><br><span class="line">        root = Tk()</span><br><span class="line">        root.title(<span class="string">&#x27;getfilegui&#x27;</span>)</span><br><span class="line">        labels = [<span class="string">&#x27;Server Name&#x27;</span>, <span class="string">&#x27;Port Number&#x27;</span>, <span class="string">&#x27;File&#x27;</span>]</span><br><span class="line">        Form.__init__(self, labels, root)</span><br><span class="line">        self.oneshot = oneshot</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">onSubmit</span>(<span class="params">self</span>):</span><br><span class="line">        Form.onSubmit(self)</span><br><span class="line">        portnumber = self.content[<span class="string">&#x27;Port Number&#x27;</span>].get()</span><br><span class="line">        servername = self.content[<span class="string">&#x27;Server Name&#x27;</span>].get()</span><br><span class="line">        filename = self.content[<span class="string">&#x27;File&#x27;</span>].get()</span><br><span class="line">        get_filepath_from_server.get_filepath_from_server(servername, portnumber, filename)</span><br><span class="line">        showinfo(<span class="string">&#x27;getfilegui&#x27;</span>, <span class="string">&#x27;Process Complete&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> self.oneshot: Tk().quit()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    GetFilePathForm()</span><br><span class="line">    mainloop()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>articles</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>常见统计函数</title>
    <url>/2023/04/07/statistic-function/</url>
    <content><![CDATA[<h3 id="单点分布">单点分布：</h3>
<p><span class="math display">\[ f(X = x)=\begin{cases}1, &amp; x =
c\\0, &amp; x \neq c\end{cases} \]</span></p>
<p>c, 为常数， 数学期望C，方差</p>
<h3 id="两点分布">两点分布：</h3>
<p><span class="math display">\[ f(X = k)=\begin{cases}p, &amp;
\text{k=0}\\q, &amp; \text{k=1}\end{cases}  \]</span></p>
<span id="more"></span>
<p>数学期望p, 方差pq</p>
<h3 id="二项分布-bnp">二项分布 <span
class="math display">\[B(n,p)\]</span>:</h3>
<p><span class="math display">\[P(X=k)=C_n^kp^kq^{n-k}, k =
0,1,...,n\]</span></p>
<p>数学期望p,方差pq</p>
<h3 id="泊松分布-plambda">泊松分布 <span
class="math display">\[P(\lambda)\]</span>:</h3>
<p><span
class="math display">\[P(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},k =
0,1,...,n, \lambda \gt 0\]</span></p>
<p>数学期望<span class="math display">\[\lambda\]</span>,方差<span
class="math display">\[\lambda\]</span></p>
<h3 id="几何分布">几何分布：</h3>
<p><span class="math display">\[P(X=K) = q^{k-1}p,k = 1,2,...,
0&lt;p&lt;1, p+q =1\]</span></p>
<h3 id="超几何分布">超几何分布</h3>
<p><span class="math display">\[P(X=K) =
\frac{C_M^kC_{N-M}^{n-k}}{C_N^n},k = 1,2,..., min(M,N), M \leq N
\]</span></p>
<p>数学期望<span class="math display">\[\frac{nM}{N}\]</span></p>
<p>方差<span
class="math display">\[\frac{nM}{N}(1-\frac{M}{N}).\frac{N-n}{N-1}\]</span></p>
<h3 id="帕斯卡分布">帕斯卡分布</h3>
<p><span class="math display">\[P(X=k)=C_{k-1}^{r-1}p^rq^{k-r},
k=r,r+1,..., 0&lt;p&lt;1,p+q=1\]</span></p>
<p>数学期望：<span class="math display">\[\frac{r}{p}\]</span>
方差：<span class="math display">\[\frac{rq}{p^2}\]</span></p>
<!-- more -->
<h2 id="常见连续型分布">常见连续型分布</h2>
<h3 id="均匀分布">均匀分布</h3>
<p><span class="math display">\[ f(x)=\begin{cases}\frac{1}{b-a}, &amp;
x \in (a,b)\\0, &amp; x \notin (a,b)\end{cases} \]</span></p>
<h3 id="指数分布">指数分布</h3>
<p><span class="math display">\[ f(x)=\begin{cases}\lambda e^{-\lambda
x}, &amp; x \ge 0\\0, &amp; x \lt 0\end{cases} \]</span></p>
<h3 id="正太分布">正太分布</h3>
<p><span class="math display">\[ f(x)=\frac{1}{\sqrt{2\pi}
\sigma}e^\frac{(x-u)^2}{2\sigma}, -\infty &lt; x &lt; +\infty
\]</span></p>
<h3 id="对数正态分布">对数正态分布</h3>
<p><span class="math display">\[ f(x)=\begin{cases}\frac{1}{x\sigma
\sqrt{2\pi}}e^\frac{(ln x-u)^2}{2\sigma}, &amp; -\infty &lt; x &lt;
+\infty \\0,&amp; x \le 0 \end{cases} \]</span></p>
<h3 id="威布尔分布">威布尔分布</h3>
<p><span class="math display">\[ f(x)=\begin{cases}\alpha\lambda
x^{\alpha-1}e^{-\lambda x^\alpha}, &amp; x \gt 0 \\0,&amp; x \leq 0
\end{cases} \]</span></p>
<p>数学期望：<span
class="math display">\[\Gamma(\frac{1}{\alpha}+1)\lambda^\frac{-1}{\alpha}\]</span>
方差：<span
class="math display">\[lambda^\frac{-1}{\alpha}\[\Gamma(\frac{2}{\alpha}+1)
- \Gamma(\frac{1}{\alpha}+1)^2\]\\]</span></p>
<h3 id="伽马分布">伽马分布</h3>
<p><span class="math display">\[
B(m, n) =
\begin{cases}\frac{\beta^\alpha}{\Gamma{(\alpha)}}x^{\alpha-1}e^{-\beta
x},
&amp; x \geq 0 \\0, &amp; x \lt 0\end{cases}
\]</span></p>
<h3 id="贝塔分布">贝塔分布</h3>
<p><span class="math display">\[
B(m, n) =
\begin{cases}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma{(b)}}x^{\alpha-1}(1-x)^{b-1},
&amp; 0 &lt; x &lt; 1 \\0, \text{其它}\end{cases}
\]</span></p>
<h3 id="卡方分布">卡方分布</h3>
<p><span class="math display">\[
f(x) = \begin{cases}\frac{1}{2^{n/2}\Gamma(n/2)}
x^{n/2-1}e^{-x/2}, &amp; x \ge 0 \\0, &amp; x \lt 0\end{cases}
\]</span></p>
<h3 id="t分布">t分布</h3>
<p><span class="math display">\[
f(x)=\begin{cases}\frac{\Gamma((n+1)/2)}{\sqrt{n\pi} \Gamma{(n/2)}}
, &amp; x \ge 0 \\0, &amp; x \lt 0
\end{cases}
\]</span></p>
<h3 id="f分布">F分布</h3>
<p><span class="math display">\[
f(x)=\begin{cases}\frac{\Gamma((n+m)/2)}{\Gamma{(n/2)}\Gamma{(m/2)}}n^{n/2}m^{m/2}x^{n/2-1}(nx+m)^{\frac{n+m}{2}}
, &amp; x \ge 0 \\0, &amp; x \lt 0
\end{cases}
\]</span></p>
<h3 id="柯西分布">柯西分布</h3>
<p><span class="math display">\[
f(x)=\frac{1}{\pi}\frac{\lambda}{\lambda^2+(x-\mu)^2}, -\infty &lt; x
&lt; +\infty \]</span></p>
<h3 id="二维正太分布分布函数等备注">二维正太分布分布函数等，备注：</h3>
<p><span class="math display">\[\Gamma 函数,
\Gamma(\alpha)=\int_0^{+\infty} x^{\alpha-1}e^{-x}dx,\alpha \gt 0
\]</span> <span class="math display">\[B(Beta) 函数, B(p,q)=\int_0^1
x^{p-1}(1-x)^{q-1}dx,p \gt 0, q \gt 0 \]</span></p>
]]></content>
      <categories>
        <category>articles</category>
        <category>统计</category>
      </categories>
      <tags>
        <tag>statistic</tag>
      </tags>
  </entry>
  <entry>
    <title>视频内容相似度算法</title>
    <url>/2023/04/07/%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>随着视频内容越来越多，通过深度模型理解视频，提取视频内容特征，建立视频搜索引擎，已经成为主流。视频内容相似度检索以及视频内容理解能力越发重要。再业务推进过程以及技术积累过程中，对调研尝试过的数据和方法，做简要的整理和剖析。北大满哥视频侵权，说明平台在视频内容审核这一块，严格意义上讲，就平台再视频版权这一块，或多或少的都需要人工运维去做支撑（依据没有运用OCR以及语义等初级的文案审核能力对头部流量视频做内容风控）。显然目前互联网企业的初衷，还在我们的"菜篮子"里，未将精力投入的科技的星辰大海，个人观点。
<span id="more"></span> ## 视频相似问题</p>
<h2 id="处理问题规模">处理问题规模</h2>
<p>常见的算法都需要的对每帧图片内容做编码，单帧（或者视频段）处理速度，对最终的推理耗时影响很大；比如，单帧耗时指视频流拉取至内存以及单帧图片特征提取耗时（视频读取平均一帧，20ms）；
<strong>(视频)20000 * 帧数（2*60*25）* 单帧耗时50ms/1000/60/60 ~=
833小时；</strong></p>
<h2 id="常见的视频相似度问题">常见的视频相似度问题</h2>
<p><strong>码率变化，格式变化，添加透明水印（少量），分辨率变化，添加文本，裁剪，明显水印，边界扩充；视频内容存在交集，裁剪，边界扩充问题示例。</strong></p>
<p>这里容易出现起义的问题就是，视频段存在交集（episode
内容copy）；视频内容存在交集(episode
内容趋同，同样的交互内容）；比如最近北大满哥视频抄袭事件，是需要更复杂的语义理解能力，比如语音识别能力，对抄袭文案进行，识别。然当前所有平台再视频版权这一块，或多或少的都需要人工运维去做支撑。如前面所说，目前的互联网企业，还是觊觎我们的"菜篮子"，未将精力投入的科技的星辰大海。</p>
<h2 id="数据集">数据集</h2>
<h2 id="开源数据集">开源数据集</h2>
<p>视频+文本</p>
<ul>
<li><a href="https://paperswithcode.com/dataset/msvd">Microsoft Research
Video Description Corpus</a> <a
href="https://paperswithcode.com/dataset/msvd">(MSVD)</a>：也称为YouTube2Text
dataset，该数据集同样由Microsoft Research提供，地址为 Microsoft Research
Video Description Corpus
。该数据集包含1970段YouTube视频片段（时长在10-25s之间），每段视频被标注了大概40条英文句子。</li>
<li><a href="https://paperswithcode.com/dataset/msr-vtt">MSR-VTT
(Microsoft Research Video to</a> <a
href="https://paperswithcode.com/dataset/msr-vtt">Text)</a>：该数据集为ACM
Multimedia 2016 的 Microsoft Research - Video to Text (MSR-VTT)
Challenge。地址为 Microsoft Multimedia Challenge
。该数据集包含10000个视频片段（video
clip），被分为训练，验证和测试集三部分。每个视频片段都被标注了大概20条英文句子。此外，MSR-VTT还提供了每个视频的类别信息（共计20类），这个类别信息算是先验的，在测试集中也是已知的。同时，视频都是包含音频信息的。该数据库共计使用了四种机器翻译的评价指标，分别为：METEOR,
BLEU@1-4,ROUGE-L,CIDEr。</li>
<li><a href="https://paperswithcode.com/dataset/lsmdc">LSMDC (Large
Scale Movie Description</a> <a
href="https://paperswithcode.com/dataset/lsmdc">Challenge)</a>: This
dataset contains 118,081 short video clips extracted from 202 movies.
Each video has a caption, either extracted from the movie script or from
transcribed DVS (descriptive video services) for the visually impaired.
The validation set contains 7408 clips and evaluation is performed on a
test set of 1000 videos from movies disjoint from the training and val
sets.</li>
</ul>
<p>视频</p>
<ul>
<li><a href="http://vireo.cs.cityu.edu.hk/webvideo/">CC_WEB_VIDEO</a> -
Near-Duplicate Video Retrieval</li>
<li><a href="http://ndd.iti.gr/fivr/">FIVR-5K, FIVR-200K</a> -
Fine-grained Incident Video Retrieval</li>
<li><a href="http://pascal.inrialpes.fr/data/evve/">EVVE</a> -
Event-based Video Retrieval</li>
<li><a href="http://activity-net.org/">ActivityNet</a> - Action Video
Retrieval</li>
</ul>
<p>竞赛视频数据</p>
<ul>
<li><a href="https://algo.browser.qq.com/">QQ Browser 2021 Ai Algorithm
Competition</a></li>
<li>也可以在这里下载：https://share.weiyun.com/S7YSt5sp
密码：78u5bw</li>
</ul>
<p>开放生产数据</p>
<ul>
<li><a href="https://github.com/alipay/VCSL">VCSL
数据集和评测以及算法代码</a></li>
<li>https://github.com/alipay/VCSL</li>
</ul>
<h2 id="业界方案">业界方案</h2>
<h2 id="抖音视频检索能力">抖音视频检索能力</h2>
<ul>
<li>https://www.volcengine.com/product/videohighlights
<strong>开放能力</strong>：通过多模态AI算法提取精彩片段并剪除重复内容，将其浓缩为精华摘要短视频，应用于广告投放、游戏投放、教育等场景。
<strong>分析</strong>：多模态算法只用于视频片段内去重，不支持大量视频的检索；</li>
</ul>
<figure>
<img
src="https://pic1.zhimg.com/80/v2-6def731ea4d2e38bbe1e7d3ae02236d8_720w.png?source=d16d100b"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>编辑</p>
<p>Image</p>
<h2 id="百度视频检索能力">百度视频检索能力</h2>
<ul>
<li>https://cloud.baidu.com/doc/MMS/s/Gkbhphdtw</li>
</ul>
<figure>
<img
src="https://picx.zhimg.com/80/v2-fdfa6caf8dec6de79a662d30440f4f6d_720w.png?source=d16d100b"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>编辑</p>
<p>Image</p>
<h2 id="阿里云开放视频检索能力">阿里云开放视频检索能力</h2>
<ul>
<li>https://retina.aliyun.com/?spm=5176.11914242.J_5253785160.4.57354b57sY8Oed#/DNA/sport</li>
</ul>
<figure>
<img
src="https://picx.zhimg.com/80/v2-fafa6a85209948f79e287081c973cfdb_720w.png?source=d16d100b"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>编辑</p>
<p>Image</p>
<h2 id="算法方案">算法方案</h2>
<h3 id="基于视频编码的">基于视频编码的</h3>
<ul>
<li>https://github.com/MKLab-ITI/visil</li>
<li>Video Similarity and Alignment Learning on Partial Video Copy
Detection</li>
<li>https://arxiv.org/pdf/2108.01817v1.pdf</li>
<li>https://pvcd-vsal.github.io/vsal//results/</li>
</ul>
<h3 id="基于视频画面-文本联合编码">基于视频画面-文本联合编码</h3>
<ul>
<li>https://github.com/willard-yuan/video-text-retrieval-papers</li>
</ul>
<h3 id="基于视频画面-语音联合编码">基于视频画面-语音联合编码</h3>
<ul>
<li>待补充完善</li>
</ul>
<h3 id="开源方案">开源方案</h3>
<p>https://milvus.io/cn/docs/v2.0.0/video_similarity_search.md</p>
<h2 id="常用算法">常用算法</h2>
<p>一般提取视频特征分成两步：</p>
<ul>
<li>帧级特征提取，视频画面，或者音频片段特征提取；</li>
<li>再获取帧级特征表示后，需要一个时间对齐模，揭示潜在复制视频对之间一个或多个复制片段的相似性和时间范围；</li>
</ul>
<h3 id="帧级特征获取">帧级特征获取</h3>
<p>从第一步来看，视频检索本质上是对重复画面或者语音片段等的检索识别，从对底层的特征编码能力角度，常见视频相似度查找算法如下；</p>
<table>
<colgroup>
<col style="width: 26%" />
<col style="width: 26%" />
<col style="width: 47%" />
</colgroup>
<thead>
<tr class="header">
<th>视频相似度度量方案</th>
<th>方法分类</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MD5,SHA-256</td>
<td>哈希算法</td>
<td>只能分析完全相同内容</td>
</tr>
<tr class="even">
<td>dHash/aHash/pHash, PDQ</td>
<td>传统图像感知方案</td>
<td>对裁剪、翻转等具有一定的鲁棒性</td>
</tr>
<tr class="odd">
<td>深度hash 方案</td>
<td>深度hash感知</td>
<td>对裁剪、翻转，灰度化等都具有较强的鲁棒性</td>
</tr>
<tr class="even">
<td>RMAC,DINO</td>
<td>基于深度的图像特征编码</td>
<td>对于图像篡改具有较强的鲁棒性</td>
</tr>
<tr class="odd">
<td>图文预训练模型</td>
<td>深度多模态</td>
<td>指标依赖于数据量</td>
</tr>
<tr class="even">
<td>图音预训练模型</td>
<td>深度多模态</td>
<td>待补充</td>
</tr>
</tbody>
</table>
<p>从第二步来看，将上述视频内容进行帧级特征表示，需要分析视频对之间一个或多个复制片段的相似性，并确定时间范围</p>
<h3 id="经典时空建模方法如下">经典时空建模方法如下</h3>
<ul>
<li>Temporal Hough Voting</li>
<li>graph-based Temporal Network</li>
<li><a
href="https://iris.unimore.it/bitstream/11380/1155754/2/1517.pdf">temporal
matching kernel</a></li>
<li><a
href="https://iris.unimore.it/bitstream/11380/1155754/2/1517.pdf">LAMV</a></li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li>https://richzhang.github.io/PerceptualSimilarity/index_files/poster_cvpr.pdf</li>
<li>Poullot S , Tsukatani S , Nguyen A P , et al. Temporal Matching
Kernel with Explicit Feature Maps[C]// Acm International Conference on
Multimedia. ACM, 2015.</li>
<li>L. Baraldi, M. Douze, R. Cucchiara, and H. Jegou. Lamv :Learning to
align and match videos with kernelized temporal layers. In 2018 IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 7804–7813,
2018. 1, 2, 3**</li>
<li>M. Douze, H. Jegou, and C. Schmid. An image-based approach to video
copy detection with spatio-temporal postfiltering. IEEE Transactions on
Multimedia, 12(4):257–266,2010. 3, 7</li>
<li>Hung-Khoon Tan, Chong-Wah Ngo, Richard Hong, and TatSeng Chua.
Scalable detection of partial near-duplicate videos by visual-temporal
consistency. MM ’09, page 145–154, New York, NY, USA, 2009. Association
for Computing Machinery. 3, 7</li>
</ul>
<blockquote>
<p>本文使用 <a href="https://zhuanlan.zhihu.com/p/106057556">Zhihu On
VSCode</a> 创作并发布</p>
</blockquote>
]]></content>
      <categories>
        <category>视频处理</category>
        <category>数字指纹</category>
        <category>视频相似度</category>
      </categories>
      <tags>
        <tag>statistic</tag>
      </tags>
  </entry>
</search>
